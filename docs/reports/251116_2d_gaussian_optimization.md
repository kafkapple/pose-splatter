# 2D Gaussian Splatting ìµœì í™” ê°€ì´ë“œ - 2025-11-16

## Executive Summary

2D Gaussian Splatting ë Œë”ëŸ¬ì˜ gradient ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì„±ëŠ¥ ìµœì í™”ë¥¼ ì§„í–‰í–ˆìœ¼ë‚˜, **ë©”ëª¨ë¦¬ ì œì•½**ìœ¼ë¡œ ì¸í•´ ëŒ€ê·œëª¨ ì´ë¯¸ì§€ì—ì„œëŠ” ì‹¤í–‰ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.

**í•µì‹¬ ë°œê²¬**:
- âœ… Gradient propagation ë¬¸ì œ í•´ê²° ì™„ë£Œ
- âœ… ë²¡í„°í™” ë° ìºì‹± ìµœì í™” ì™„ë£Œ
- âŒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ~2-3GB per forward pass (RTX 3060 12GB í•œê³„)
- âš ï¸ 2D GSëŠ” ë³¸ì§ˆì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì§‘ì•½ì  (ì „ì²´ ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ ìƒì„±)

---

## 1. ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²°

### 1.1 Gradient Propagation ë¬¸ì œ

**ì¦ìƒ**:
```python
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
```

**ê·¼ë³¸ ì›ì¸**:
- In-place ì—°ì‚° (`canvas[...] += ...`, `alpha_canvas[...] += ...`)ì´ autograd graphë¥¼ ëŠìŒ
- Python for loopì—ì„œ ë§¤ë²ˆ ìƒˆë¡œìš´ í…ì„œ ìƒì„±/ë³µì‚¬ë¡œ ì¸í•œ ë¹„íš¨ìœ¨

**í•´ê²°ì±…** (`src/gaussian_renderer.py:266-424`):

1. **Non-leaf tensor ì´ˆê¸°í™”**:
   ```python
   # Before: leaf tensor (in-place ì—°ì‚° ë¶ˆê°€)
   canvas = torch.zeros(...)
   
   # After: non-leaf tensor (in-place ì—°ì‚° ê°€ëŠ¥)
   canvas = torch.zeros(...) + 0.0  # Creates computation graph
   ```

2. **Vectorized rendering**:
   - ëª¨ë“  Gaussiansë¥¼ í•œ ë²ˆì— ê³„ì‚° (ë°°ì¹˜ ì²˜ë¦¬)
   - Grid caching: `meshgrid()` ì¬ì‚¬ìš©
   - Broadcastingìœ¼ë¡œ ë³‘ë ¬ ê³„ì‚°

3. **Memory-efficient accumulation**:
   ```python
   # In-place add (non-leaf tensorì´ë¯€ë¡œ gradient ìœ ì§€)
   canvas.add_(contribution.unsqueeze(-1) * colors[i])
   alpha_canvas.add_(contribution)
   ```

### 1.2 ì„±ëŠ¥ ìµœì í™”

**Before (Sequential Implementation)**:
- ê° Gaussianë§ˆë‹¤:
  - Bounding box ê³„ì‚°
  - Local meshgrid ìƒì„±
  - Gaussian weights ê³„ì‚°
  - Canvas ì—…ë°ì´íŠ¸ (clone í•„ìš”)
- **ì†ë„**: ~4ì´ˆ/batch (10 batches = 57ì´ˆ)

**After (Vectorized Implementation)**:
- ì „ì²´ image gridë¥¼ cacheí•˜ê³  ì¬ì‚¬ìš©
- Batch ë‹¨ìœ„ë¡œ Gaussians ì²˜ë¦¬
- **ì†ë„**: ì´ë¡ ì ìœ¼ë¡œ 2-3ë°° í–¥ìƒ (ë©”ëª¨ë¦¬ í—ˆìš© ì‹œ)

**ìµœì í™” ìš”ì†Œ**:
1. Grid caching: `self._cached_grids`
2. Batch processing: `batch_size` íŒŒë¼ë¯¸í„°
3. Broadcasting: ì „ì²´ ì—°ì‚° GPU ë³‘ë ¬í™”

---

## 2. ë©”ëª¨ë¦¬ ë¶„ì„

### 2.1 ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ ê³„ì‚°

**ì„¤ì •**:
- Image size: 1024 Ã— 1152 Ã· 4 = 256 Ã— 288
- Grid size: 112
- Batch size: B

**ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**:

| Component | Shape | Size (FP32) | Note |
|-----------|-------|-------------|------|
| Image grid (cached) | [2, 1, H, W] | 2 Ã— 256 Ã— 288 Ã— 4B = ~0.6MB | âœ… Cached |
| Gaussian params | [N, 9] | Variable | Input |
| Per batch processing | [B, H, W] | B Ã— 256 Ã— 288 Ã— 4B | **Major bottleneck** |
| Canvas | [H, W, 3] | 256 Ã— 288 Ã— 3 Ã— 4B = ~0.9MB | âœ… Fixed |
| Alpha canvas | [H, W] | 256 Ã— 288 Ã— 4B = ~0.3MB | âœ… Fixed |

**Batch sizeë³„ ë©”ëª¨ë¦¬**:
- B = 1: ~0.3MB per Gaussian
- B = 10: ~3MB per batch
- B = 100: ~30MB per batch

**ë¬¸ì œ**:
- Forward pass: ~1-2GB
- Backward pass (gradients): 2-3ë°° ì¶”ê°€
- **Total**: 3-6GB per training iteration

### 2.2 GPU ë©”ëª¨ë¦¬ ì œì•½ (RTX 3060 12GB)

**ì‹¤ì œ ì‚¬ìš©ëŸ‰**:
```
Config: grid_size=112, image_downsample=4, batch_size=10
Result: CUDA OOM (tried to allocate 2-30MB, but 11.09GB already used)
```

**ë©”ëª¨ë¦¬ ë¶„í•´**:
- PyTorch base: ~500MB
- Model (UNet): ~2-3GB
- Data loading: ~1-2GB
- Optimizer states: ~2-3GB
- **2D Renderer forward**: ~2-3GB âŒ
- **Backward (gradients)**: ~3-4GB âŒ

**ê²°ë¡ **: RTX 3060 12GBë¡œëŠ” `grid_size=112`, `image_downsample=4` ì„¤ì • ë¶ˆê°€ëŠ¥

---

## 3. ê¶Œì¥ ì„¤ì •

### 3.1 Small-Scale ì„¤ì • (12GB GPU)

**Config ìˆ˜ì •** (`configs/debug/2d_3d_comparison_2d_debug.json`):
```json
{
  "image_downsample": 8,        // 4 â†’ 8 (128 Ã— 144)
  "grid_size": 64,               // 112 â†’ 64
  "max_frames": 20,              // 30 â†’ 20
  "batch_size": 1                // Renderer batch size = 1
}
```

**ì˜ˆìƒ ë©”ëª¨ë¦¬**:
- Image: 128 Ã— 144 â†’ 0.15MB per Gaussian
- Forward: ~500MB
- Backward: ~1GB
- **Total**: ~4-5GB âœ… ê°€ëŠ¥

### 3.2 Medium-Scale ì„¤ì • (24GB GPU)

```json
{
  "image_downsample": 4,
  "grid_size": 96,
  "max_frames": 30,
  "batch_size": 5
}
```

### 3.3 Large-Scale ì„¤ì • (40GB+ GPU)

```json
{
  "image_downsample": 2,
  "grid_size": 112,
  "max_frames": 50,
  "batch_size": 10
}
```

---

## 4. Troubleshooting

### 4.1 CUDA OOM ë°œìƒ ì‹œ

**ì¦ìƒ**:
```
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate X MB.
```

**í•´ê²° ìˆœì„œ**:

1. **GPU ë©”ëª¨ë¦¬ í™•ì¸**:
   ```bash
   nvidia-smi
   # Memory-Usage: XX MiB / 12288 MiB
   ```

2. **í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ**:
   ```bash
   pkill -9 -f "train_script.py"
   pkill -9 -f "python"
   ```

3. **ì„¤ì • ì¶•ì†Œ**:
   - `image_downsample`: 4 â†’ 6 â†’ 8
   - `grid_size`: 112 â†’ 96 â†’ 64
   - `max_frames`: 30 â†’ 20 â†’ 10
   - `batch_size` (renderer): 10 â†’ 5 â†’ 1

4. **ìºì‹œ ì •ë¦¬**:
   ```bash
   torch.cuda.empty_cache()  # Pythonì—ì„œ
   ```

### 4.2 Gradient ë¬¸ì œ ì¬ë°œ ì‹œ

**ì¦ìƒ**:
```
RuntimeError: element 0 of tensors does not require grad
```

**í™•ì¸ ì‚¬í•­**:
1. `canvas`, `alpha_canvas`ê°€ non-leaf tensorì¸ì§€ í™•ì¸:
   ```python
   canvas = torch.zeros(...) + 0.0  # âœ… Non-leaf
   # Not: torch.zeros(..., requires_grad=True)  # âŒ Leaf
   ```

2. In-place ì—°ì‚°ì´ non-leaf tensorì—ë§Œ ì ìš©ë˜ëŠ”ì§€ í™•ì¸:
   ```python
   canvas.add_(...)  # âœ… OK if canvas is non-leaf
   canvas += ...     # âŒ May break gradient
   ```

### 4.3 ëŠë¦° í•™ìŠµ ì†ë„

**ì¦ìƒ**:
- 10 batchesì— 60ì´ˆ+ ì†Œìš”
- GPU utilization < 50%

**ì›ì¸ ë° í•´ê²°**:

1. **Grid cache ë¯¸ì‚¬ìš©**:
   ```python
   # Check if cached:
   if not hasattr(self, '_cached_grids'):
       # Grid is being recreated every time!
   ```

2. **Batch size ë„ˆë¬´ ì‘ìŒ**:
   - `batch_size=1`: ë©”ëª¨ë¦¬ ì•ˆì „í•˜ì§€ë§Œ ëŠë¦¼
   - `batch_size=5-10`: ê· í˜•ì  ì°¾ê¸°
   - ë©”ëª¨ë¦¬ í—ˆìš© ë²”ìœ„ ë‚´ì—ì„œ ìµœëŒ€í™”

3. **CPU ë³‘ëª©**:
   ```bash
   # num_workers í™•ì¸
   num_workers: 4  # DataLoaderì—ì„œ
   ```

---

## 5. 3D Gaussian Splattingê³¼ ë¹„êµ

### 5.1 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

| Feature | 2D GS (Custom) | 3D GS (gsplat) |
|---------|----------------|----------------|
| Implementation | Python + PyTorch | C++ + CUDA |
| Image grid | Full [B, H, W] | Sparse rasterization |
| Memory | ~2-3GB forward | ~500MB forward |
| Speed | ~4s/batch | ~0.1s/batch |
| GPU | 12GB+ required | 8GB+ sufficient |

### 5.2 ì‚¬ìš© ê¶Œì¥

**2D Gaussian Splatting ì‚¬ìš© ì¡°ê±´**:
- âœ… Small images (< 128Ã—128)
- âœ… Few Gaussians (< 1000)
- âœ… Large GPU (24GB+)
- âœ… ì—°êµ¬/ì‹¤í—˜ ëª©ì 

**3D Gaussian Splatting ì‚¬ìš© ì¡°ê±´**:
- âœ… Production í™˜ê²½
- âœ… Large images (256Ã—256+)
- âœ… Many Gaussians (10K+)
- âœ… ì„±ëŠ¥ ì¤‘ìš”

---

## 6. ì½”ë“œ ë³€ê²½ ì‚¬í•­

### 6.1 ì£¼ìš” ìˆ˜ì • íŒŒì¼

**`src/gaussian_renderer.py`**:

1. **Line 235-258**: `batch_size` íŒŒë¼ë¯¸í„° ì¶”ê°€
2. **Line 266-331**: `render()` ë©”ì„œë“œ - vectorizedë¡œ ì „í™˜
3. **Line 336-424**: `_render_vectorized()` - ë°°ì¹˜ ì²˜ë¦¬ ë° ìºì‹±
4. **Line 354-360**: Grid caching êµ¬í˜„
5. **Line 366-376**: Non-leaf tensor ì´ˆê¸°í™”
6. **Line 413-423**: In-place accumulation

### 6.2 ì‚¬ìš© ì˜ˆì‹œ

```python
from src.gaussian_renderer import create_renderer

# Create 2D renderer with custom batch size
renderer = create_renderer(
    mode="2d",
    width=288,
    height=256,
    device="cuda",
    batch_size=5,  # Adjust based on GPU memory
    sigma_cutoff=3.0
)

# Render
gaussian_params = model.generate_gaussians(...)  # [N, 9]
rgb, alpha = renderer.render(
    gaussian_params,
    viewmat,  # Not used in 2D
    K         # Not used in 2D
)
```

---

## 7. í–¥í›„ ê°œì„  ë°©í–¥

### 7.1 ë‹¨ê¸° (1-2ì£¼)

1. **Sparse Rendering**:
   - Bounding box clippingìœ¼ë¡œ ì˜ì—­ ì œí•œ
   - Only render Gaussians within image bounds

2. **Depth Sorting**:
   - Proper alpha blending order
   - Z-ordering by Gaussian depth

### 7.2 ì¤‘ê¸° (1-2ê°œì›”)

1. **CUDA Kernel êµ¬í˜„**:
   - Custom CUDA kernel for splatting
   - Tile-based rendering (gsplat ë°©ì‹)
   - ì˜ˆìƒ ì†ë„ í–¥ìƒ: 10-50ë°°

2. **Adaptive Batching**:
   - Dynamic batch size based on available memory
   - Automatic memory profiling

### 7.3 ì¥ê¸° (3-6ê°œì›”)

1. **Hybrid Rendering**:
   - 2D for foreground, 3D for background
   - Multi-resolution rendering

2. **Quantization**:
   - FP16 or INT8 for Gaussian parameters
   - Memory reduction: 2-4ë°°

---

## 8. Quick Reference

### 8.1 ì„¤ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

**í•™ìŠµ ì‹œì‘ ì „ í™•ì¸**:
- [ ] GPU ë©”ëª¨ë¦¬ í™•ì¸: `nvidia-smi`
- [ ] Config ê²€ì¦:
  - [ ] `image_downsample`: 8 ì´ìƒ (12GB GPU)
  - [ ] `grid_size`: 64 ì´í•˜ (12GB GPU)
  - [ ] `max_frames`: 20 ì´í•˜
- [ ] Environment ì„¤ì •:
  - [ ] `export PYTHONPATH="/path/to/pose-splatter:${PYTHONPATH}"`
  - [ ] `export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True`
- [ ] Conda í™˜ê²½: `conda activate splatter`

### 8.2 ì‹¤í–‰ ëª…ë ¹ì–´

**2D Gaussian (Small Scale)**:
```bash
conda run -n splatter python scripts/training/train_script.py \
  configs/debug/2d_3d_comparison_2d_debug_small.json \
  --epochs 10
```

**3D Gaussian (Recommended)**:
```bash
conda run -n splatter python scripts/training/train_script.py \
  configs/debug/2d_3d_comparison_3d_debug.json \
  --epochs 10
```

### 8.3 ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§

```python
import torch

# Before training
print(f"GPU memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f}GB")
print(f"GPU memory reserved: {torch.cuda.memory_reserved() / 1e9:.2f}GB")

# After each epoch
torch.cuda.empty_cache()
```

---

## 9. ê²°ë¡ 

**2D Gaussian Splatting í˜„í™©**:
- âœ… Gradient propagation ì™„ì „ í•´ê²°
- âœ… ì„±ëŠ¥ ìµœì í™” ì™„ë£Œ (ë²¡í„°í™”, ìºì‹±)
- âš ï¸ ë©”ëª¨ë¦¬ ì œì•½ìœ¼ë¡œ ëŒ€ê·œëª¨ ì‹¤í—˜ ë¶ˆê°€ (12GB GPU)
- âœ… Small-scale ì‹¤í—˜ ê°€ëŠ¥ (`image_downsample=8`, `grid_size=64`)

**ì‹¤ìš©ì  ê¶Œì¥**:
1. **ì—°êµ¬/ì‹¤í—˜**: 2D GS (ì‘ì€ ì„¤ì •)
2. **Production/ëŒ€ê·œëª¨**: 3D GS (gsplat ë¼ì´ë¸ŒëŸ¬ë¦¬)
3. **ë¹„êµ ì‹¤í—˜**: 3D GSë§Œ ì‚¬ìš©í•˜ì—¬ baseline í™•ë³´

---

ğŸ“ **ë¬¸ì„œ**: `docs/reports/251116_2d_gaussian_optimization.md`  
ğŸ”— **ê´€ë ¨ ì½”ë“œ**: `src/gaussian_renderer.py:214-424`  
âš™ï¸ **ì„¤ì •**: `configs/debug/2d_3d_comparison_2d_debug.json`  
ğŸ“Š **ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼**: RTX 3060 12GB ê¸°ì¤€

**ì‘ì„±ì¼**: 2025-11-16  
**ì‘ì„±ì**: Claude Code (Anthropic)
