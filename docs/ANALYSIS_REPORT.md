# ğŸ“Š Pose Splatter í”„ë¡œì íŠ¸ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2025-11-08
**ë²„ì „**: 1.0
**í”„ë¡œì íŠ¸**: Pose Splatter (NeurIPS 2025)

---

## ëª©ì°¨
1. [ì—°êµ¬ ë°°ê²½ ë° ëª©ì ](#1-ì—°êµ¬-ë°°ê²½-ë°-ëª©ì )
2. [í•µì‹¬ ëª¨ë¸ íŒŒì´í”„ë¼ì¸](#2-í•µì‹¬-ëª¨ë¸-íŒŒì´í”„ë¼ì¸)
3. [ë°ì´í„° ì…ì¶œë ¥ êµ¬ì¡°](#3-ë°ì´í„°-ì…ì¶œë ¥-êµ¬ì¡°)
4. [ì‹¤í–‰ íŒŒì´í”„ë¼ì¸](#4-ì‹¤í–‰-íŒŒì´í”„ë¼ì¸)
5. [í•™ìŠµ ê³¼ì •](#5-í•™ìŠµ-ê³¼ì •)
6. [í•„ìš” í™˜ê²½ ì„¤ì •](#6-í•„ìš”-í™˜ê²½-ì„¤ì •)
7. [ëˆ„ë½ëœ ê¸°ëŠ¥ ë¶„ì„](#7-ëˆ„ë½ëœ-ê¸°ëŠ¥-ë¶„ì„)
8. [ìš°ì„ ìˆœìœ„ë³„ ì‹¤í–‰ ê³„íš](#8-ìš°ì„ ìˆœìœ„ë³„-ì‹¤í–‰-ê³„íš)
9. [ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—…](#9-ì¦‰ì‹œ-ì‹¤í–‰-ê°€ëŠ¥í•œ-ì‘ì—…)
10. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ](#10-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…-ê°€ì´ë“œ)

---

## 1. ì—°êµ¬ ë°°ê²½ ë° ëª©ì 

### 1.1 ë…¼ë¬¸ ì •ë³´
- **ì œëª©**: Pose Splatter: A 3D Gaussian Splatting Model for Quantifying Animal Pose and Appearance
- **ì €ì**: Jack Goffinet*, Youngjo Min*, Carlo Tomasi, David E. Carlson (* equal contribution)
- **ì¶œíŒ**: NeurIPS 2025
- **arXiv**: https://arxiv.org/abs/2505.18342

### 1.2 í•µì‹¬ í˜ì‹ 
- **Shape Carving + 3D Gaussian Splatting** ê¸°ë°˜ ë™ë¬¼ ìì„¸ ì¶”ì • í”„ë ˆì„ì›Œí¬
- ìˆ˜ë™ ì£¼ì„ ë° í”„ë ˆì„ë³„ ìµœì í™” ë¶ˆí•„ìš”
- ë™ë¬¼ ê¸°í•˜í•™ ì‚¬ì „ ì§€ì‹ ì—†ì´ ì‘ë™
- íšŒì „ ë¶ˆë³€ ì‹œê° ì„ë² ë”© ì œê³µ
- ì¥, ì¥, í˜¸í•‘ìƒˆ ë“± ë‹¤ì–‘í•œ ë™ë¬¼ì— ì ìš© ê°€ëŠ¥

### 1.3 ê¸°ëŒ€ íš¨ê³¼
> "ëŒ€ê·œëª¨, ì¢…ë‹¨ì  í–‰ë™ ë¶„ì„ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ìœ ì „í˜•, ì‹ ê²½ í™œë™, ë¯¸ì„¸ í–‰ë™ì„ ì „ë¡€ ì—†ëŠ” í•´ìƒë„ë¡œ ë§¤í•‘"

---

## 2. í•µì‹¬ ëª¨ë¸ íŒŒì´í”„ë¼ì¸

### 2.1 ì „ì²´ ì•„í‚¤í…ì²˜

```
Multi-view Images + Silhouettes
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Shape Carving Module        â”‚ â†’ 3D Volume [4, n1, n2, n3]
â”‚  (src/shape_carver.py)       â”‚   - Channel 0: Occupancy
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   - Channel 1-3: RGB colors
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3D U-Net Stack (Ã— 3)        â”‚ â†’ Refined Volume [8, n1, n2, n3]
â”‚  (src/unet_3d.py)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gaussian Parameter Network  â”‚ â†’ Per-voxel Gaussian params
â”‚  (MLP: 8â†’128â†’14)             â”‚   - Quats (4D), Scales (3D)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   - Opacities (1D), Colors (3D)
    â†“                                - Delta means (3D)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3D Gaussian Splatting       â”‚ â†’ Rendered Image [H, W, 3]
â”‚  (gsplat.rendering)          â”‚   + Alpha mask [H, W, 1]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ìƒì„¸

#### A. Shape Carving Module (`src/shape_carver.py:ShapeCarver`)

**ëª©ì **: ë‹¤ì¤‘ ì‹œì  ì‹¤ë£¨ì—£ ì´ë¯¸ì§€ë¡œë¶€í„° 3D volume ìƒì„±

**ì…ë ¥**:
- `mask`: [C, 1, H, W] - ê° ì¹´ë©”ë¼ ì‹œì ì˜ ì‹¤ë£¨ì—£ ë§ˆìŠ¤í¬
- `rgb`: [C, 3, H, W] - ê° ì¹´ë©”ë¼ ì‹œì ì˜ RGB ì´ë¯¸ì§€
- `center`: [3] - 3D ê³µê°„ì˜ ì¤‘ì‹¬ ì¢Œí‘œ
- `angle`: scalar - zì¶• íšŒì „ ê°ë„

**ì¶œë ¥**:
- `volume`: [4, n1, n2, n3] - 4ì±„ë„ 3D volume

**í•µì‹¬ ì•Œê³ ë¦¬ì¦˜**:
1. **Grid ìƒì„± ë° ë³€í™˜** (`create_3d_grid`):
   - ê· ì¼í•œ 3D voxel grid ìƒì„±
   - íšŒì „(angle)ê³¼ ì´ë™(center) ì ìš©

2. **íˆ¬ì˜ ë° ìƒ˜í”Œë§** (`project_points_torch`):
   - ê° voxelì„ ëª¨ë“  ì¹´ë©”ë¼ì— íˆ¬ì˜
   - ì¹´ë©”ë¼ ë‚´ë¶€/ì™¸ë¶€ íŒŒë¼ë¯¸í„° ì‚¬ìš©

3. **ê°€ì‹œì„± ê²°ì •** (`ray_cast_visibility_torch`):
   - Ray castingìœ¼ë¡œ occluded voxel íŒë³„
   - torch_scatterë¡œ íš¨ìœ¨ì  êµ¬í˜„

4. **ìƒ‰ìƒ ê³„ì‚°** (`compute_voxel_colors_torch`):
   - ê°€ì‹œì  ì¹´ë©”ë¼ì˜ ê°€ì¤‘ í‰ê· 
   - ë¹„ê°€ì‹œ ì¹´ë©”ë¼ëŠ” ë‚®ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬

**ì½”ë“œ ìœ„ì¹˜**: `src/shape_carver.py:308-381`

---

#### B. 3D U-Net (`src/unet_3d.py:Unet3D`)

**ëª©ì **: Volume feature ì¶”ì¶œ ë° refinement

**ì•„í‚¤í…ì²˜**:
```
Input [4, n1, n2, n3]
  â†“
Encoder (5 levels)
  - Conv3d + BatchNorm + LeakyReLU (Ã—2) per level
  - MaxPool3d for downsampling
  - Base filters: 8 â†’ 16 â†’ 32 â†’ 64 â†’ 128
  â†“
Bottleneck MLP
  - Flatten â†’ Linear(128Ã—n_prod, 512) â†’ ReLU â†’ Linear(512, 512)
  â†“
Decoder (4 levels)
  - ConvTranspose3d for upsampling
  - Skip connections from encoder
  - Conv3d + BatchNorm + LeakyReLU (Ã—2) per level
  â†“
Final Conv: 8 â†’ out_channels (default: 8)
Output [8, n1, n2, n3]
```

**íŠ¹ì§•**:
- **Skip connections**: U-Net êµ¬ì¡°ë¡œ detail ë³´ì¡´
- **Identity initialization** (`init_unet_primary_skip`):
  - ì´ˆê¸°ì— ì…ë ¥ì„ ê±°ì˜ ê·¸ëŒ€ë¡œ í†µê³¼
  - ì•ˆì •ì ì¸ í•™ìŠµ ì‹œì‘
- **Residual design**: ì…ë ¥ ì±„ë„ì„ ì¶œë ¥ì— ì§ì ‘ ë³µì‚¬

**í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
- `base_filters`: 8 (ê¸°ë³¸ê°’)
- `z_dim`: 512 (latent dimension)
- `input_size`: [80, 80, 48] (ì˜ˆì‹œ, volume_idxì— ë”°ë¼ ë³€í•¨)

**ì½”ë“œ ìœ„ì¹˜**: `src/unet_3d.py:75-168`

---

#### C. Gaussian Parameter Network

**ëª©ì **: Volume feature â†’ 3D Gaussian íŒŒë¼ë¯¸í„° ë³€í™˜

**êµ¬ì¡°**:
```python
nn.Sequential(
    nn.Linear(out_channels, 128),  # out_channels = 8
    nn.ReLU(),
    nn.Linear(128, 14),           # 14 = 4+3+1+3+3
)
```

**ì¶œë ¥ íŒŒë¼ë¯¸í„°** (14-dim per voxel):
- **Quaternions** (4D): Gaussianì˜ íšŒì „ (ì •ê·œí™” í•„ìš”)
- **Scales** (3D): ê° ì¶• ë°©í–¥ í¬ê¸° (exp ì ìš© í›„ ì‚¬ìš©)
- **Opacities** (1D): ë¶ˆíˆ¬ëª…ë„ [0, 1]
- **Colors** (3D): RGB ìƒ‰ìƒ (sigmoid â†’ [0, 1])
- **Delta means** (3D): voxel ì¤‘ì‹¬ì—ì„œ ë¯¸ì„¸ ì¡°ì • (tanh ì‚¬ìš©)

**í›„ì²˜ë¦¬**:
```python
colors = sigmoid(colors).clamp(0.0, 0.99)
scales = exp(scales + scale_offset)  # scale_offset â‰ˆ -5.5
opacities = sigmoid((probs[mask] - threshold) / (1 - threshold))
means = grid_centers[mask] + 2 * voxel_size * tanh(delta_means)
```

**ì½”ë“œ ìœ„ì¹˜**: `src/model.py:89-94, 167-200`

---

#### D. 3D Gaussian Splatting

**ëª©ì **: Gaussian primitivesë¥¼ 2D ì´ë¯¸ì§€ë¡œ ë Œë”ë§

**ë¼ì´ë¸ŒëŸ¬ë¦¬**: `gsplat.rendering.rasterization`
- ë¯¸ë¶„ ê°€ëŠ¥í•œ rasterization
- íš¨ìœ¨ì ì¸ GPU êµ¬í˜„
- Real-time rendering ìµœì í™”

**ë Œë”ë§ ê³¼ì •**:
1. Gaussiansë¥¼ ì¹´ë©”ë¼ ì¢Œí‘œê³„ë¡œ ë³€í™˜
2. 2Dë¡œ íˆ¬ì˜ (covariance matrix ê³„ì‚°)
3. Tile-based rasterization
4. Alpha blending (ì•ì—ì„œ ë’¤ë¡œ ì •ë ¬)

**ì¶œë ¥**:
```python
rgb = render + (1 - alpha) * background_color  # [1, H, W, 3]
alpha = [1, H, W, 1]
```

**ì½”ë“œ ìœ„ì¹˜**: `src/model.py:220-246`

---

## 3. ë°ì´í„° ì…ì¶œë ¥ êµ¬ì¡°

### 3.1 ì›ë³¸ ë°ì´í„° í˜•ì‹

**ë¹„ë””ì˜¤ ë°ì´í„°**:
```
data_directory/
â”œâ”€â”€ Camera1/
â”‚   â””â”€â”€ 0.mp4           # RGB video
â”œâ”€â”€ Camera2/
â”‚   â””â”€â”€ 0.mp4
â”œâ”€â”€ ...
â”œâ”€â”€ Camera6/
â”‚   â””â”€â”€ 0.mp4
â””â”€â”€ mask_videos/
    â”œâ”€â”€ 1.mp4           # Silhouette masks (grayscale)
    â”œâ”€â”€ 2.mp4
    â”œâ”€â”€ ...
    â””â”€â”€ 6.mp4
```

**ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜** (`camera_params_*.h5`):
```
HDF5 structure:
/camera_parameters/
  â”œâ”€â”€ rotation: [C, 3, 3]      # íšŒì „ í–‰ë ¬
  â”œâ”€â”€ translation: [C, 3]      # ì´ë™ ë²¡í„°
  â””â”€â”€ intrinsic: [C, 3, 3]     # ë‚´ë¶€ íŒŒë¼ë¯¸í„° (fx, fy, cx, cy)
```

**Config íŒŒì¼ ì˜ˆì‹œ** (`configs/mouse_4.json`):
```json
{
  "data_directory": "/path/to/data/mouse/",
  "project_directory": "/path/to/project/mouse_4_cameras/",
  "mask_video_fns": ["mask_videos/1.mp4", ..., "mask_videos/6.mp4"],
  "video_fns": ["Camera1/0.mp4", ..., "Camera6/0.mp4"],
  "holdout_views": [5, 1],
  "image_width": 2048,
  "image_height": 1536,
  "image_downsample": 4,
  "fps": 30,
  "frame_jump": 5,
  "ell": 0.22,
  "grid_size": 112,
  "volume_idx": [[0, 96], [16, 96], [25, 89]],
  "lr": 1e-4,
  "img_lambda": 0.5,
  "ssim_lambda": 0.0
}
```

### 3.2 ì „ì²˜ë¦¬ëœ ë°ì´í„° í˜•ì‹

**ì´ë¯¸ì§€ ë°ì´í„°** (`images.h5` â†’ `images.zarr`):
```
Shape: [N_frames, C_cameras, H, W, 3]
Dtype: uint8
Compression: gzip (level 2)
Storage: Zarr (for efficient random access)
```

**ìì„¸ ë°ì´í„°** (`center_rotation.npz`):
```python
{
  "centers": [N_frames, 3],    # 3D center coordinates
  "angles": [N_frames],         # Z-axis rotation angles
}
```

### 3.3 ë°ì´í„° ë¡œë” (`src/data.py:FrameDataset`)

**ì¶œë ¥ í˜•ì‹**:
```python
mask:     torch.Tensor [C, H, W]          # Binary silhouettes
img:      torch.Tensor [C, 3, H, W]       # RGB images (normalized to [0,1])
p_3d:     torch.Tensor [3]                # 3D center
angle:    float                           # Rotation angle (radians)
view_idx: int                             # Camera index to render
```

**ë°ì´í„° ë¶„í• **:
- **Train**: frames 0 ~ N/3
- **Valid**: frames N/3 ~ 2N/3
- **Test**: frames 2N/3 ~ N

**ì½”ë“œ ìœ„ì¹˜**: `src/data.py:15-77`

---

## 4. ì‹¤í–‰ íŒŒì´í”„ë¼ì¸

### 4.1 ì „ì²˜ë¦¬ ë‹¨ê³„ (Steps 1-5)

```bash
# Step 1: ì¹´ë©”ë¼ Up Direction ì¶”ì •
python estimate_up_direction.py config.json
# ì¶œë ¥: vertical_lines.npz (up vector)

# Step 2: ê° í”„ë ˆì„ì˜ ì¤‘ì‹¬ ë° íšŒì „ ê³„ì‚°
python calculate_center_rotation.py config.json
# ì¶œë ¥: center_rotation.npz (centers, angles)

# Step 3: Volume crop ì¸ë±ìŠ¤ ê²°ì •
python calculate_crop_indices.py config.json
# ì¶œë ¥: volume_sum.npy
# ì½˜ì†”ì— volume_idx ì¶œë ¥ â†’ config.jsonì— ìˆ˜ë™ ì…ë ¥

# Step 4: ì´ë¯¸ì§€ë¥¼ HDF5ë¡œ ì €ì¥
python write_images.py config.json
# ì¶œë ¥: images/images.h5 [N, C, H, W, 3]

# Step 5: HDF5 â†’ Zarr ë³€í™˜
python copy_to_zarr.py images/images.h5 images/images.zarr
# ì¶œë ¥: images/images.zarr (í•™ìŠµ ì‹œ ì‚¬ìš©)
```

### 4.2 í•™ìŠµ ë‹¨ê³„ (Step 6)

```bash
# ê¸°ë³¸ í•™ìŠµ
python train_script.py config.json --epochs 50

# Ablation ì‹¤í—˜ (U-Net ì—†ì´)
python train_script.py config.json --epochs 50 --ablation

# ì¤‘ë‹¨ëœ í•™ìŠµ ì¬ê°œ
python train_script.py config.json --load --epochs 100

# ë””ë²„ê·¸ ëª¨ë“œ (ë¹ ë¥¸ ê²€ì¦)
python train_script.py config.json --epochs 5 --max_batches 50
```

**ì¶œë ¥**:
- `project_directory/reconstruction.pdf`: ì˜ˆì¸¡ ì´ë¯¸ì§€
- `project_directory/loss.pdf`: í•™ìŠµ ê³¡ì„ 
- `project_directory/checkpoint.pt`: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸

### 4.3 í‰ê°€ ë° ì¶”ë¡  ë‹¨ê³„ (Steps 7-10)

```bash
# Step 7: ì •ëŸ‰ì  í‰ê°€
python evaluate_model.py config.json
# ì¶œë ¥: rendered_images.h5, metrics_test.csv

# Step 8: ë‹¨ì¼ ì´ë¯¸ì§€ ë Œë”ë§
python render_image.py config.json <frame_num> <view_num>
# ì˜ˆ: python render_image.py config.json 100 0
# ì¶œë ¥: renders/render_100_0_0.0_0.0_0.0_0.0.png

# Step 8 (ê³ ê¸‰): ìì„¸ ë³€í˜•
python render_image.py config.json 100 0 \
    --angle_offset 0.5 \
    --delta_x 0.1 --delta_y 0.0 --delta_z 0.05

# Step 9: Visual features ê³„ì‚°
python calculate_visual_features.py config.json
# ì¶œë ¥: features.npy

# Step 10: Visual embedding ê³„ì‚°
python calculate_visual_embedding.py config.json
# ì¶œë ¥: embedding.npy
```

---

## 5. í•™ìŠµ ê³¼ì •

### 5.1 ì†ì‹¤ í•¨ìˆ˜

**ì´ ì†ì‹¤**:
```python
total_loss = iou_loss + ssim_loss + img_loss
```

**1. IoU Loss (ì‹¤ë£¨ì—£ ë§¤ì¹­)**:
```python
def get_iou_loss(pred_alpha, target_mask, eps=1e-6):
    intersection = (pred_alpha * target_mask).sum()
    union = (pred_alpha + target_mask - pred_alpha * target_mask).sum()
    iou = (intersection + eps) / (union + eps)
    return 1 - iou
```
- ëª©ì : ë Œë”ë§ëœ alpha maskì™€ GT silhouette ì¼ì¹˜
- ë²”ìœ„: [0, 1]

**2. SSIM Loss (êµ¬ì¡°ì  ìœ ì‚¬ë„)**:
```python
ssim_loss = ssim_lambda * (1.0 - SSIM(pred_img, target_img))
```
- ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™” (`ssim_lambda = 0.0`)
- í™œì„±í™” ì‹œ ì´ë¯¸ì§€ êµ¬ì¡° ë³´ì¡´

**3. Image Loss (L1 í”½ì…€ ì°¨ì´)**:
```python
img_loss = img_lambda * torch.abs(target_img - pred_img).sum() / mask.sum()
```
- ë§ˆìŠ¤í¬ ì˜ì—­ ë‚´ì—ì„œë§Œ ê³„ì‚°
- `img_lambda = 0.5` (ê¸°ë³¸ê°’)

### 5.2 í•™ìŠµ ì•Œê³ ë¦¬ì¦˜

**Optimizer**: Adam
- Learning rate: `1e-4` (ê¸°ë³¸ê°’)
- No learning rate scheduling

**í•™ìŠµ ë£¨í”„**:
```python
for epoch in range(n_epochs):
    for mask, img, p_3d, angle, view_idx in train_loader:
        # Forward
        rgb, alpha = model(mask, img, p_3d, angle, view_idx)

        # Loss
        loss = iou_loss + img_loss + ssim_loss

        # Backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    # Validation (every valid_every epochs)
    if epoch % valid_every == 0:
        val_loss = calculate_validation_loss(...)

    # Visualization (every plot_every epochs)
    if epoch % plot_every == 0:
        plot_predictions(...)
        plot_losses(...)

    # Checkpoint (every save_every epochs)
    if epoch % save_every == 0:
        torch.save({...}, checkpoint_fn)
```

### 5.3 ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|--------|------|
| `lr` | 1e-4 | Learning rate |
| `img_lambda` | 0.5 | Image loss weight |
| `ssim_lambda` | 0.0 | SSIM loss weight (ë³´í†µ 0) |
| `valid_every` | 5 | Validation ì£¼ê¸° (epochs) |
| `plot_every` | 1 | Visualization ì£¼ê¸° |
| `save_every` | 1 | Checkpoint ì €ì¥ ì£¼ê¸° |
| `image_downsample` | 4 | ì´ë¯¸ì§€ í•´ìƒë„ ê°ì†Œ ë¹„ìœ¨ |
| `ell` | 0.22 | Volume í¬ê¸° (m) |
| `grid_size` | 112 | Voxel í•´ìƒë„ |
| `min_n` | 1024 | ìµœì†Œ Gaussian ê°œìˆ˜ |
| `max_n` | 16000 | ìµœëŒ€ Gaussian ê°œìˆ˜ |
| `num_unets` | 3 | U-Net ê°œìˆ˜ |

---

## 6. í•„ìš” í™˜ê²½ ì„¤ì •

### 6.1 í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

**ìµœì†Œ ì‚¬ì–‘**:
- GPU: NVIDIA GPU with CUDA support (8GB+ VRAM)
- RAM: 16GB+
- Storage: 50GB+ (ë°ì´í„°ì…‹ í¬ê¸°ì— ë”°ë¼)

**ê¶Œì¥ ì‚¬ì–‘**:
- GPU: NVIDIA RTX 3090 / A100 (24GB+ VRAM)
- RAM: 32GB+
- Storage: 100GB+ SSD

**CUDA ì•„í‚¤í…ì²˜**:
- ì½”ë“œì— í•˜ë“œì½”ë”©: `os.environ['TORCH_CUDA_ARCH_LIST'] = "8.6"`
- Ampere (3000 series) ì´ìƒ ê¶Œì¥
- ë‹¤ë¥¸ GPU ì‚¬ìš© ì‹œ í•´ë‹¹ ë¼ì¸ ìˆ˜ì • í•„ìš”

### 6.2 ì†Œí”„íŠ¸ì›¨ì–´ ì˜ì¡´ì„±

**í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬**:
```
python >= 3.10
torch >= 2.0.0
pytorch-cuda = 11.8
gsplat                    # 3D Gaussian Splatting
torch-scatter             # Sparse scatter operations
zarr                      # Chunked array storage
h5py                      # HDF5 file format
opencv-python (cv2)       # Video processing
torchmetrics              # SSIM, PSNR ë“±
matplotlib                # Visualization
Pillow                    # Image I/O
tqdm                      # Progress bars
joblib                    # Parallel processing
```

**ì„¤ì¹˜ ë°©ë²• (Conda)**:
```bash
# 1. í™˜ê²½ ìƒì„±
conda create -n pose-splatter python=3.10 -y
conda activate pose-splatter

# 2. PyTorch (CUDA 11.8)
conda install pytorch==2.0.0 torchvision==0.15.0 pytorch-cuda=11.8 -c pytorch -c nvidia -y

# 3. gsplat (source ë¹Œë“œ í•„ìš”í•  ìˆ˜ ìˆìŒ)
pip install gsplat

# 4. torch-scatter
pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html

# 5. ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install zarr h5py opencv-python torchmetrics matplotlib Pillow tqdm joblib
```

### 6.3 í™˜ê²½ ê²€ì¦

```bash
# CUDA í™•ì¸
python -c "import torch; print('CUDA available:', torch.cuda.is_available()); print('Device:', torch.cuda.get_device_name(0))"

# ë¼ì´ë¸ŒëŸ¬ë¦¬ import í…ŒìŠ¤íŠ¸
python -c "import gsplat; import torch_scatter; import zarr; print('All imports OK')"

# ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸
python -c "from src.model import PoseSplatter; print('Model import OK')"
```

---

## 7. ëˆ„ë½ëœ ê¸°ëŠ¥ ë¶„ì„

### 7.1 README Checklist

```markdown
### Project Checklist
- [x] Code on GitHub
- [ ] Camera-ready on arXiv
- [ ] Add links to data          â† ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë§í¬ ì—†ìŒ
- [ ] Add more detailed usage    â† ìƒì„¸ ì‚¬ìš©ë²• ë¶€ì¡±
```

### 7.2 ëˆ„ë½ëœ íŒŒì¼ ë° ë¬¸ì„œ

**1. í™˜ê²½ ì„¤ì • íŒŒì¼**:
- âŒ `requirements.txt`
- âŒ `environment.yml`
- âŒ `setup.py` ë˜ëŠ” `pyproject.toml`

**2. ë°ì´í„°ì…‹ ê´€ë ¨**:
- âŒ ì˜ˆì œ ë°ì´í„°ì…‹ (ì‘ì€ ìƒ˜í”Œì´ë¼ë„)
- âŒ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°©ë²• ë¬¸ì„œ
- âŒ ë°ì´í„° ìˆ˜ì§‘ ê°€ì´ë“œ
- âŒ ë°ì´í„° í¬ë§· ëª…ì„¸

**3. ë¬¸ì„œí™”**:
- âŒ API ë¬¸ì„œ (Docstrings ë¶€ì¡±)
- âŒ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì´ë“œ
- âŒ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ
- âš ï¸ Config íŒŒë¼ë¯¸í„° ì„¤ëª… (ì¼ë¶€ë§Œ ì¡´ì¬)

**4. ì‹œê°í™” ë„êµ¬**:
- âš ï¸ `plot_voxels.py` ì¡´ì¬í•˜ì§€ë§Œ ì‚¬ìš©ë²• ë¶ˆëª…í™•
- âŒ 3D volume viewer
- âŒ Gaussian primitives ì‹œê°í™”
- âŒ í•™ìŠµ ì§„í–‰ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

### 7.3 ì½”ë“œ ê°œì„  í•„ìš” ì‚¬í•­

**1. í•˜ë“œì½”ë”©ëœ ê°’**:
```python
# train_script.py:23, evaluate_model.py:21, render_image.py:18
os.environ['TORCH_CUDA_ARCH_LIST'] = "8.6"  # â† íŠ¹ì • GPU ì•„í‚¤í…ì²˜ ê³ ì •
```
â†’ Configë¡œ ì´ë™ ë˜ëŠ” ìë™ ê°ì§€ í•„ìš”

**2. ì—ëŸ¬ í•¸ë“¤ë§ ë¶€ì¡±**:
- íŒŒì¼ ì—†ì„ ë•Œ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ë¶€ì¡±
- GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ëŒ€ì‘ ì½”ë“œ ì—†ìŒ
- Config ê²€ì¦ ë¡œì§ ë¯¸í¡

**3. ì£¼ì„ ë° ë¬¸ì„œí™”**:
- Docstring ê±°ì˜ ì—†ìŒ (ì¼ë¶€ íŒŒì¼ë§Œ ì¡´ì¬)
- Type hints ë¶€ì¡±
- ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ ì„¤ëª… ë¶€ì¡±

**4. í™•ì¥ì„±**:
- ì¹´ë©”ë¼ ê°œìˆ˜ í•˜ë“œì½”ë”© (C=6 ê°€ì •)
- ë‹¤ì–‘í•œ ë™ë¬¼ ì¢…ì— ëŒ€í•œ ìë™ ì„¤ì • ë¶€ì¡±

### 7.4 êµ¬í˜„ ê¶Œì¥ ì‚¬í•­

**ìš°ì„ ìˆœìœ„: ë†’ìŒ**
1. âœ… `requirements.txt` ì‘ì„±
2. âœ… í™˜ê²½ ì„¤ì • ê°€ì´ë“œ ì‘ì„±
3. âœ… Config íŒŒë¼ë¯¸í„° ì„¤ëª… ë¬¸ì„œ
4. âš ï¸ ì˜ˆì œ ë°ì´í„° ë˜ëŠ” ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ

**ìš°ì„ ìˆœìœ„: ì¤‘ê°„**
5. 3D ì‹œê°í™” ë„êµ¬ ê°œì„ 
6. TensorBoard í†µí•©
7. Checkpoint resume ë¡œì§ ê°œì„ 
8. ë°ì´í„° ì „ì²˜ë¦¬ ìë™í™”

**ìš°ì„ ìˆœìœ„: ë‚®ìŒ**
9. Docker ì´ë¯¸ì§€ ì œê³µ
10. Weights & Biases í†µí•©
11. Multi-GPU í•™ìŠµ ì§€ì›
12. ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

---

## 8. ìš°ì„ ìˆœìœ„ë³„ ì‹¤í–‰ ê³„íš

### Phase 1: í™˜ê²½ êµ¬ì¶• â­â­â­ (í•„ìˆ˜)

**ì†Œìš” ì‹œê°„**: 30ë¶„ ~ 1ì‹œê°„

**ë‹¨ê³„**:
1. **Conda í™˜ê²½ ìƒì„±**:
   ```bash
   conda create -n pose-splatter python=3.10 -y
   conda activate pose-splatter
   ```

2. **PyTorch ì„¤ì¹˜** (CUDA 11.8):
   ```bash
   conda install pytorch==2.0.0 torchvision==0.15.0 pytorch-cuda=11.8 -c pytorch -c nvidia -y
   ```

3. **gsplat ì„¤ì¹˜**:
   ```bash
   pip install gsplat
   # ì‹¤íŒ¨ ì‹œ: pip install gsplat --no-cache-dir
   ```

4. **torch-scatter ì„¤ì¹˜**:
   ```bash
   pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
   ```

5. **ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬**:
   ```bash
   pip install zarr h5py opencv-python torchmetrics matplotlib Pillow tqdm joblib
   ```

6. **ì„¤ì¹˜ ê²€ì¦**:
   ```bash
   python -c "import torch; print('CUDA:', torch.cuda.is_available(), torch.cuda.get_device_name(0))"
   python -c "import gsplat, torch_scatter, zarr; print('All OK')"
   python -c "from src.model import PoseSplatter; print('Model OK')"
   ```

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] Conda í™˜ê²½ ìƒì„± ì™„ë£Œ
- [ ] PyTorch CUDA ì‚¬ìš© ê°€ëŠ¥
- [ ] gsplat ì„¤ì¹˜ ì™„ë£Œ
- [ ] torch-scatter ì„¤ì¹˜ ì™„ë£Œ
- [ ] ëª¨ë“  ì˜ì¡´ì„± import ì„±ê³µ

---

### Phase 2: ë°ì´í„° ì¤€ë¹„ â­â­â­ (í•„ìˆ˜)

**ì†Œìš” ì‹œê°„**: ë³€ë™ (ë°ì´í„° í™•ë³´ì— ë”°ë¼)

**í˜„ì¬ ìƒí™©**: ê³µê°œ ë°ì´í„°ì…‹ ë§í¬ ì—†ìŒ âŒ

**ì˜µì…˜ A: ì €ìì—ê²Œ ë°ì´í„° ìš”ì²­**
```bash
# GitHub Issue ìƒì„±
# ì œëª©: "[Data Request] Sample dataset for reproduction"
# ë‚´ìš©:
# - ì‘ì€ ì˜ˆì œ ë°ì´í„° ìš”ì²­ (1-2ë¶„ ë¶„ëŸ‰)
# - ë˜ëŠ” ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë§í¬ ìš”ì²­
```

**ì˜µì…˜ B: ìì²´ ë°ì´í„° ìˆ˜ì§‘**

**í•„ìš” ì¥ë¹„**:
- ìµœì†Œ 4ê°œ, ê¶Œì¥ 6ê°œ ì¹´ë©”ë¼
- ë™ê¸°í™” ê°€ëŠ¥í•œ ì„¤ì •
- ê· ì¼í•œ ì¡°ëª…

**ë°ì´í„° ìˆ˜ì§‘ ì ˆì°¨**:
1. **ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜**:
   - ì²´ì»¤ë³´ë“œ íŒ¨í„´ ì‚¬ìš©
   - OpenCV `calibrateCamera` í•¨ìˆ˜
   - ì¶œë ¥: ë‚´ë¶€/ì™¸ë¶€ íŒŒë¼ë¯¸í„°

2. **ë¹„ë””ì˜¤ ì´¬ì˜**:
   - ë™ë¬¼ í–‰ë™ ë…¹í™”
   - ëª¨ë“  ì¹´ë©”ë¼ ë™ê¸°í™”
   - ë°°ê²½ ì œê±° ê°€ëŠ¥í•œ ì„¤ì • ê¶Œì¥

3. **ì‹¤ë£¨ì—£ ë§ˆìŠ¤í¬ ìƒì„±**:
   - ë°°ê²½ ì°¨ë¶„ ë˜ëŠ” ë”¥ëŸ¬ë‹ ì„¸ê·¸ë©˜í…Œì´ì…˜
   - ë°”ì´ë„ˆë¦¬ ë§ˆìŠ¤í¬ (0 ë˜ëŠ” 255)

**ì˜µì…˜ C: ê³µê°œ Multi-view ë°ì´í„°ì…‹ í™œìš©**
- CMU Panoptic Dataset
- DeepLabCut 3D ë°ì´í„°
- (ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í¬í•¨ í•„ìš”)

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ì›ë³¸ ë¹„ë””ì˜¤ í™•ë³´ (RGB Ã— C)
- [ ] ì‹¤ë£¨ì—£ ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ
- [ ] ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ
- [ ] Config íŒŒì¼ ì‘ì„± (ê²½ë¡œ ìˆ˜ì •)

---

### Phase 3: ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ â­â­ (ë°ì´í„° í™•ë³´ í›„)

**ì†Œìš” ì‹œê°„**: 1-3ì‹œê°„ (ë¹„ë””ì˜¤ ê¸¸ì´ì— ë”°ë¼)

**ì „ì œ ì¡°ê±´**: Phase 2 ì™„ë£Œ

**ì‹¤í–‰ ìˆœì„œ**:

```bash
# 0. Config íŒŒì¼ ìˆ˜ì •
# - data_directory: ë¹„ë””ì˜¤ ê²½ë¡œ
# - project_directory: ì¶œë ¥ ê²½ë¡œ
# - mask_video_fns, video_fns: íŒŒì¼ ì´ë¦„

# 1. Up direction ì¶”ì • (1-5ë¶„)
python estimate_up_direction.py config.json
# ì¶œë ¥: vertical_lines.npz

# 2. Center & Rotation ê³„ì‚° (5-15ë¶„)
python calculate_center_rotation.py config.json
# ì¶œë ¥: center_rotation.npz

# 3. Volume crop ì¸ë±ìŠ¤ ê²°ì • (5-10ë¶„)
python calculate_crop_indices.py config.json
# ì½˜ì†” ì¶œë ¥ì—ì„œ volume_idx í™•ì¸
# â†’ config.jsonì— ìˆ˜ë™ ì…ë ¥

# 4. ì´ë¯¸ì§€ HDF5 ì €ì¥ (30ë¶„ - 2ì‹œê°„)
python write_images.py config.json
# ì¶œë ¥: images/images.h5
# ë³‘ë ¬ ì²˜ë¦¬ (CPU ì½”ì–´ ìˆ˜ë§Œí¼)

# 5. ZARR ë³€í™˜ (10-30ë¶„)
python copy_to_zarr.py images/images.h5 images/images.zarr
# ì¶œë ¥: images/images.zarr
```

**ë””ë²„ê¹… íŒ**:
- ê° ë‹¨ê³„ ì¶œë ¥ íŒŒì¼ í¬ê¸° í™•ì¸
- `volume_idx`ê°€ ì´ìƒí•˜ë©´ `calculate_crop_indices.py` ì¬ì‹¤í–‰
- ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ `frame_jump` ì¦ê°€

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] vertical_lines.npz ìƒì„±
- [ ] center_rotation.npz ìƒì„±
- [ ] volume_idx í™•ì¸ ë° config ì—…ë°ì´íŠ¸
- [ ] images.h5 ìƒì„± í™•ì¸
- [ ] images.zarr ìƒì„± í™•ì¸

---

### Phase 4: ëª¨ë¸ í•™ìŠµ â­â­ (ì „ì²˜ë¦¬ ì™„ë£Œ í›„)

**ì†Œìš” ì‹œê°„**: ìˆ˜ ì‹œê°„ ~ ìˆ˜ ì¼ (ë°ì´í„° í¬ê¸°, GPU ì„±ëŠ¥ì— ë”°ë¼)

**ë””ë²„ê·¸ ëª¨ë“œ (ë¨¼ì € ì‹¤í–‰ ê¶Œì¥)**:
```bash
# ì‘ì€ ë°°ì¹˜ë¡œ ë¹ ë¥¸ ê²€ì¦
python train_script.py config.json --epochs 5 --max_batches 50
# ì†Œìš”: 5-10ë¶„
# ëª©ì :
# - ë°ì´í„° ë¡œë”© ì •ìƒ í™•ì¸
# - forward/backward pass ì„±ê³µ í™•ì¸
# - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
```

**ì „ì²´ í•™ìŠµ**:
```bash
# ê¸°ë³¸ í•™ìŠµ (50 epochs)
python train_script.py config.json --epochs 50
# ì†Œìš”: ìˆ˜ ì‹œê°„ (GPU, ë°ì´í„° í¬ê¸°ì— ë”°ë¼)

# Ablation ì‹¤í—˜
python train_script.py config.json --epochs 50 --ablation
# U-Net ì—†ì´ í•™ìŠµ (ë¹„êµìš©)

# ì¤‘ë‹¨ëœ í•™ìŠµ ì¬ê°œ
python train_script.py config.json --load --epochs 100
```

**ëª¨ë‹ˆí„°ë§**:
```bash
# ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸
watch -n 60 "ls -lh project_directory/*.{pdf,pt}"

# GPU ì‚¬ìš©ëŸ‰
watch -n 1 nvidia-smi
```

**ì¶œë ¥ íŒŒì¼**:
- `reconstruction.pdf`: ì˜ˆì¸¡ í’ˆì§ˆ (ë§¤ epoch)
- `loss.pdf`: í•™ìŠµ/ê²€ì¦ ê³¡ì„ 
- `checkpoint.pt`: ëª¨ë¸ ê°€ì¤‘ì¹˜

**ì¤‘ë‹¨ ì¡°ê±´**:
- Validation lossê°€ ìˆ˜ë ´
- Train lossëŠ” ê°ì†Œí•˜ì§€ë§Œ validation loss ì¦ê°€ (overfitting)

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ë””ë²„ê·¸ ëª¨ë“œ ì„±ê³µ
- [ ] í•™ìŠµ loss ê°ì†Œ í™•ì¸
- [ ] Reconstruction í’ˆì§ˆ ê°œì„  í™•ì¸
- [ ] Checkpoint ì •ìƒ ì €ì¥
- [ ] GPU ë©”ëª¨ë¦¬ overflow ì—†ìŒ

---

### Phase 5: í‰ê°€ ë° ì‹œê°í™” â­ (í•™ìŠµ ì™„ë£Œ í›„)

**ì†Œìš” ì‹œê°„**: 30ë¶„ ~ 2ì‹œê°„

**ì •ëŸ‰ì  í‰ê°€**:
```bash
# ëª¨ë“  test frames ë Œë”ë§ ë° ë©”íŠ¸ë¦­ ê³„ì‚°
python evaluate_model.py config.json
# ì¶œë ¥:
# - rendered_images.h5: [N_test, C, H, W, 4]
# - metrics_test.csv: IoU, SSIM, PSNR, L1

# CSV í™•ì¸
cat project_directory/metrics_test.csv
```

**ì •ì„±ì  í‰ê°€ (ì´ë¯¸ì§€ ë Œë”ë§)**:
```bash
# ë‹¨ì¼ í”„ë ˆì„, ë‹¨ì¼ ì‹œì 
python render_image.py config.json 100 0
# ì¶œë ¥: renders/render_100_0_0.0_0.0_0.0_0.0.png

# ë‹¤ì–‘í•œ ê°ë„
for angle in 0.0 0.5 1.0; do
  python render_image.py config.json 100 0 --angle_offset $angle
done

# ìœ„ì¹˜ ë³€í™”
python render_image.py config.json 100 0 \
  --delta_x 0.1 --delta_y 0.0 --delta_z 0.05
```

**Novel view synthesis (holdout views)**:
```bash
# configì—ì„œ holdout_views = [5, 1]ì´ë©´
python render_image.py config.json 100 5  # ì¹´ë©”ë¼ 5
python render_image.py config.json 100 1  # ì¹´ë©”ë¼ 1
# ì´ ì‹œì ë“¤ì€ í•™ìŠµ ì¤‘ ë³´ì§€ ëª»í•¨ â†’ ì¼ë°˜í™” ì„±ëŠ¥ í™•ì¸
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ì •ëŸ‰ì  ë©”íŠ¸ë¦­ í™•ì¸ (IoU > 0.9 ê¶Œì¥)
- [ ] ë Œë”ë§ ì´ë¯¸ì§€ ì‹œê°ì  í’ˆì§ˆ í™•ì¸
- [ ] Novel view ì„±ëŠ¥ í™•ì¸
- [ ] Ablation ëª¨ë¸ê³¼ ë¹„êµ (U-Net íš¨ê³¼)

---

### Phase 6: ê³ ê¸‰ ê¸°ëŠ¥ (ì„ íƒ)

**ìš°ì„ ìˆœìœ„: ë‚®ìŒ**

**ì‹œê° íŠ¹ì§• ì¶”ì¶œ**:
```bash
# ëª¨ë“  í”„ë ˆì„ì˜ latent features
python calculate_visual_features.py config.json
# ì¶œë ¥: features.npy

# Dimensionality reduction (UMAP ë“±)
python calculate_visual_embedding.py config.json
# ì¶œë ¥: embedding.npy
```

**ì‚¬ìš© ì‚¬ë¡€**:
- Behavior clustering
- Anomaly detection
- Trajectory analysis

---

## 9. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—…

### 9.1 í™˜ê²½ ì¤€ë¹„ (ë°ì´í„° ì—†ì´ ê°€ëŠ¥) âœ…

```bash
# ì „ì²´ ìŠ¤í¬ë¦½íŠ¸
conda create -n pose-splatter python=3.10 -y
conda activate pose-splatter
conda install pytorch==2.0.0 torchvision==0.15.0 pytorch-cuda=11.8 -c pytorch -c nvidia -y
pip install gsplat torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
pip install zarr h5py opencv-python torchmetrics matplotlib Pillow tqdm joblib

# ê²€ì¦
python -c "import torch; print('CUDA:', torch.cuda.is_available())"
python -c "from src.model import PoseSplatter; print('OK')"
```

### 9.2 ì½”ë“œ ê²€ì¦ (ë°ì´í„° ì—†ì´ ê°€ëŠ¥) âœ…

```bash
# ëª¨ë¸ êµ¬ì¡° í™•ì¸
python -c "from src.model import PoseSplatter; import torch; print(PoseSplatter)"

# U-Net í…ŒìŠ¤íŠ¸
python src/unet_3d.py
# ì¶œë ¥: Initial MSE between input and first 4 output channels = ...

# Config ë¡œë”© í…ŒìŠ¤íŠ¸
python -c "from src.config_utils import Config; c = Config('configs/mouse_4.json'); print('ell:', c.ell)"

# Shape carving ëª¨ë“ˆ import
python -c "from src.shape_carver import ShapeCarver; print('OK')"
```

### 9.3 ë¬¸ì„œ ì‘ì„± (ì§€ê¸ˆ ë°”ë¡œ ê°€ëŠ¥) âœ…

**1. requirements.txt ìƒì„±**:
```bash
# í™˜ê²½ êµ¬ì¶• í›„
pip freeze > requirements.txt

# ë˜ëŠ” ìˆ˜ë™ ì‘ì„±
cat > requirements.txt << EOF
torch==2.0.0
torchvision==0.15.0
gsplat
torch-scatter
zarr
h5py
opencv-python
torchmetrics
matplotlib
Pillow
tqdm
joblib
EOF
```

**2. environment.yml ìƒì„±**:
```yaml
name: pose-splatter
channels:
  - pytorch
  - nvidia
  - conda-forge
  - defaults
dependencies:
  - python=3.10
  - pytorch=2.0.0
  - torchvision=0.15.0
  - pytorch-cuda=11.8
  - pip
  - pip:
    - gsplat
    - torch-scatter
    - zarr
    - h5py
    - opencv-python
    - torchmetrics
    - matplotlib
    - Pillow
    - tqdm
    - joblib
```

**3. ìƒì„¸ ì‚¬ìš© ê°€ì´ë“œ ì‘ì„±** (ì´ ë¬¸ì„œ)

### 9.4 ë°ì´í„° ìš”ì²­ (ì§€ê¸ˆ ë°”ë¡œ ê°€ëŠ¥) âœ…

```markdown
# GitHub Issue í…œí”Œë¦¿

Title: [Data Request] Sample dataset for reproduction

Body:
Hi @jackgoffinet @youngjomin,

Thank you for open-sourcing this excellent work! I'm trying to reproduce
the results but couldn't find the dataset download links.

Could you please provide:
1. A small sample dataset (1-2 minutes) for testing the pipeline?
2. Or links to download the full datasets (rat, mouse, finch)?
3. Documentation on the camera calibration format (camera_params_*.h5)?

This would greatly help the community reproduce and build upon your work.

Thank you!
```

---

## 10. íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

### 10.1 ì„¤ì¹˜ ë¬¸ì œ

#### ë¬¸ì œ: `gsplat` ì„¤ì¹˜ ì‹¤íŒ¨
```
ERROR: Could not build wheels for gsplat
```

**í•´ê²°**:
```bash
# CUDA ë²„ì „ í™•ì¸
nvcc --version

# ìºì‹œ ì‚­ì œ í›„ ì¬ì„¤ì¹˜
pip cache purge
pip install gsplat --no-cache-dir

# sourceì—ì„œ ë¹Œë“œ
git clone https://github.com/nerfstudio-project/gsplat.git
cd gsplat
pip install -e .
```

---

#### ë¬¸ì œ: `torch-scatter` ì„¤ì¹˜ ì‹¤íŒ¨
```
ERROR: No matching distribution found for torch-scatter
```

**í•´ê²°**:
```bash
# PyTorch ë²„ì „ í™•ì¸
python -c "import torch; print(torch.__version__)"

# í•´ë‹¹ ë²„ì „ì— ë§ëŠ” URL ì‚¬ìš©
# PyTorch 2.0.0 + CUDA 11.8:
pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html

# ë˜ëŠ” conda ì‚¬ìš©
conda install pytorch-scatter -c pyg
```

---

### 10.2 ë°ì´í„° ë¡œë”© ë¬¸ì œ

#### ë¬¸ì œ: `Zarr file does not exist`
```python
FileNotFoundError: Zarr file does not exist: /path/to/images.zarr
```

**ì›ì¸**: HDF5 â†’ Zarr ë³€í™˜ ëˆ„ë½

**í•´ê²°**:
```bash
# copy_to_zarr.py ì‹¤í–‰ í™•ì¸
python copy_to_zarr.py images/images.h5 images/images.zarr

# íŒŒì¼ ì¡´ì¬ í™•ì¸
ls -lh images/
# ê¸°ëŒ€: images.h5, images.zarr/ (ë””ë ‰í† ë¦¬)
```

---

#### ë¬¸ì œ: Config ê²½ë¡œ ì˜¤ë¥˜
```python
FileNotFoundError: [Errno 2] No such file or directory: '/path/to/data/...'
```

**ì›ì¸**: Configì— ì ˆëŒ€ ê²½ë¡œ ë˜ëŠ” ì˜ëª»ëœ ìƒëŒ€ ê²½ë¡œ

**í•´ê²°**:
```json
// config.json ìˆ˜ì •
{
  "data_directory": "/absolute/path/to/data/mouse/",
  "project_directory": "/absolute/path/to/project/mouse_4_cameras/",
  ...
}
```

---

### 10.3 GPU ë©”ëª¨ë¦¬ ë¬¸ì œ

#### ë¬¸ì œ: `CUDA out of memory`
```
torch.cuda.OutOfMemoryError: CUDA out of memory.
Tried to allocate 2.00 GiB (GPU 0; 7.79 GiB total capacity)
```

**í•´ê²° ë°©ë²• (ìš°ì„ ìˆœìœ„ ìˆœ)**:

**1. ì´ë¯¸ì§€ í•´ìƒë„ ê°ì†Œ**:
```json
// config.json
"image_downsample": 8,  // 4 â†’ 8
```

**2. Grid í•´ìƒë„ ê°ì†Œ**:
```json
"grid_size": 64,  // 112 â†’ 64
```

**3. Gaussian ê°œìˆ˜ ì œí•œ**:
```json
"max_n": 8000,  // 16000 â†’ 8000
```

**4. U-Net base filters ê°ì†Œ**:
```python
# train_script.py
model = PoseSplatter(
    ...
    base_filters=4,  # 8 â†’ 4
)
```

**5. Ablation ëª¨ë“œ ì‚¬ìš©**:
```bash
python train_script.py config.json --ablation
# U-Net ì—†ì´ í•™ìŠµ â†’ ë©”ëª¨ë¦¬ ì ˆì•½
```

---

### 10.4 í•™ìŠµ ë¬¸ì œ

#### ë¬¸ì œ: Lossê°€ ê°ì†Œí•˜ì§€ ì•ŠìŒ
```
Epoch 10: loss = 1.234 (no improvement)
```

**ì›ì¸ ë° í•´ê²°**:

**1. Learning rate ë„ˆë¬´ ë‚®ìŒ**:
```json
"lr": 1e-3,  // 1e-4 â†’ 1e-3
```

**2. Loss weights ë¶ˆê· í˜•**:
```json
"img_lambda": 1.0,   // 0.5 â†’ 1.0
"ssim_lambda": 0.1,  // 0.0 â†’ 0.1
```

**3. ë°ì´í„° ë¬¸ì œ**:
```bash
# Reconstruction ì´ë¯¸ì§€ í™•ì¸
open project_directory/reconstruction.pdf
# ì™„ì „íˆ ê²€ì •/í•˜ì–‘ì´ë©´ ë°ì´í„° ë¡œë”© ë¬¸ì œ
```

---

#### ë¬¸ì œ: Overfitting (Validation loss ì¦ê°€)
```
Epoch 30: train_loss = 0.05, val_loss = 0.20 (increasing)
```

**í•´ê²°**:

**1. Early stopping**:
```python
# Validation lossê°€ ì¦ê°€í•˜ë©´ í•™ìŠµ ì¤‘ë‹¨
```

**2. ë°ì´í„° ì¦ê°•** (ì½”ë“œ ìˆ˜ì • í•„ìš”):
```python
# FrameDataset.__getitem__ì— ì¶”ê°€
angle_offset = np.random.uniform(-0.1, 0.1)
center_offset = np.random.normal(0, 0.01, 3)
```

---

### 10.5 ë Œë”ë§ ë¬¸ì œ

#### ë¬¸ì œ: ë Œë”ë§ ì´ë¯¸ì§€ê°€ ê²€ì •ìƒ‰
```
render_100_0_0.0_0.0_0.0_0.0.png is all black
```

**ì›ì¸**:
- Gaussian ê°œìˆ˜ê°€ 0 (ëª¨ë“  voxelì´ threshold ì´í•˜)
- ì˜ëª»ëœ camera parameters

**í•´ê²°**:

**1. Threshold í™•ì¸**:
```python
# src/model.py:54-56
prob_threshold=0.25,        # ë‚®ì¶”ê¸°: 0.25 â†’ 0.1
mask_threshold=0.25,
mask_threshold_delta=0.05,
```

**2. Volume í™•ì¸**:
```python
# render_image.pyì— ë””ë²„ê·¸ ì¶”ê°€
print("Volume shape:", volume.shape)
print("Volume range:", volume.min(), volume.max())
print("Num Gaussians:", (probs > threshold).sum())
```

---

#### ë¬¸ì œ: ë Œë”ë§ì´ ë„ˆë¬´ ëŠë¦¼
```
Rendering 1 image takes 10 seconds
```

**ì›ì¸**: ë„ˆë¬´ ë§ì€ Gaussians

**í•´ê²°**:
```json
// config.json
"max_n": 8000,  // 16000 â†’ 8000
"prob_threshold": 0.3,  // 0.25 â†’ 0.3 (ë” ì ì€ Gaussians)
```

---

### 10.6 ê¸°íƒ€ ë¬¸ì œ

#### ë¬¸ì œ: `TORCH_CUDA_ARCH_LIST` ê²½ê³ 
```
Warning: CUDA arch list does not match
```

**í•´ê²°**:
```python
# train_script.py, evaluate_model.py, render_image.py
# ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ GPUì— ë§ê²Œ ìˆ˜ì •
# os.environ['TORCH_CUDA_ARCH_LIST'] = "8.6"  # RTX 3090

# GPU ì•„í‚¤í…ì²˜ í™•ì¸
nvidia-smi --query-gpu=compute_cap --format=csv
# ì¶œë ¥ ì˜ˆ: 8.6 (Ampere), 7.5 (Turing), 8.9 (Ada)
```

---

#### ë¬¸ì œ: Multi-processing ì˜¤ë¥˜
```
RuntimeError: DataLoader worker (pid 12345) is killed by signal
```

**í•´ê²°**:
```python
# train_script.py
num_workers = 0  # ë˜ëŠ” 1, 2 (len(os.sched_getaffinity(0)) ëŒ€ì‹ )
loader_kwargs = dict(batch_size=1, shuffle=True, num_workers=0)
```

---

## 11. ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„

### 11.1 í˜„ì¬ ìƒíƒœ

âœ… **ì™„ë£Œ**:
- ì½”ë“œ êµ¬ì¡° ë¶„ì„
- ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì´í•´
- ì‹¤í–‰ ì ˆì°¨ íŒŒì•…
- í™˜ê²½ ì„¤ì • ë°©ë²• ì •ë¦¬

âŒ **ë¯¸ì™„ì„±**:
- ê³µê°œ ë°ì´í„°ì…‹ ì—†ìŒ
- ì˜ˆì œ ì‹¤í–‰ ë¶ˆê°€
- ì¼ë¶€ ë¬¸ì„œ ë¶€ì¡±

### 11.2 ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥

**ì§€ê¸ˆ ë°”ë¡œ** (ë°ì´í„° ì—†ì´):
1. âœ… Conda í™˜ê²½ êµ¬ì¶•
2. âœ… ì˜ì¡´ì„± ì„¤ì¹˜
3. âœ… ì½”ë“œ import í…ŒìŠ¤íŠ¸
4. âœ… Documentation ì‘ì„±

**ë°ì´í„° í™•ë³´ í›„**:
5. â³ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
6. â³ ëª¨ë¸ í•™ìŠµ
7. â³ í‰ê°€ ë° ì‹œê°í™”

### 11.3 Next Steps

**ìš°ì„ ìˆœìœ„ 1** (í•„ìˆ˜):
- [ ] ì €ìì—ê²Œ ë°ì´í„° ìš”ì²­ (GitHub Issue)
- [ ] í™˜ê²½ êµ¬ì¶• ë° ê²€ì¦
- [ ] requirements.txt ìƒì„±

**ìš°ì„ ìˆœìœ„ 2** (ë°ì´í„° í™•ë³´ ì‹œ):
- [ ] ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
- [ ] ë””ë²„ê·¸ ëª¨ë“œë¡œ í•™ìŠµ í…ŒìŠ¤íŠ¸
- [ ] ì „ì²´ í•™ìŠµ ì‹¤í–‰

**ìš°ì„ ìˆœìœ„ 3** (í•™ìŠµ ì™„ë£Œ ì‹œ):
- [ ] ì •ëŸ‰ì  í‰ê°€
- [ ] ì‹œê°í™” ë° ë¶„ì„
- [ ] Ablation study

### 11.4 ì°¸ê³  ìë£Œ

- **ë…¼ë¬¸**: https://arxiv.org/abs/2505.18342
- **GitHub**: https://github.com/[author]/pose-splatter (ì¶”ì •)
- **gsplat**: https://github.com/nerfstudio-project/gsplat
- **3D Gaussian Splatting**: https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/

---

**ì‘ì„±ì ë…¸íŠ¸**:
ì´ ë¬¸ì„œëŠ” ì½”ë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì‹¤í–‰ ì‹œ ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë””ë²„ê·¸ ëª¨ë“œë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤.

ê³µê°œ ë°ì´í„°ì…‹ì´ ì œê³µë˜ëŠ” ëŒ€ë¡œ ì´ ê°€ì´ë“œë¥¼ ì—…ë°ì´íŠ¸í•˜ê² ìŠµë‹ˆë‹¤.
